{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析提取特征\n",
    "- data/com_training.txt：预处理过后的数据\n",
    " - 2017.03.01-2017.07.31\n",
    " - [6, 7, 8, 13, 14, 15, 16, 17, 18]\n",
    " - log1p处理\n",
    " - 填充nan值\n",
    " - 5049000 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/home/chenzh/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_ID</th>\n",
       "      <th>date</th>\n",
       "      <th>time_interval_begin</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>imputation1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:00:00</td>\n",
       "      <td>1.657881</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:02:00</td>\n",
       "      <td>1.658394</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:04:00</td>\n",
       "      <td>1.672953</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:06:00</td>\n",
       "      <td>1.676887</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:08:00</td>\n",
       "      <td>1.680537</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:10:00</td>\n",
       "      <td>1.629241</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:12:00</td>\n",
       "      <td>1.629241</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:14:00</td>\n",
       "      <td>1.629241</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:16:00</td>\n",
       "      <td>1.695692</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:18:00</td>\n",
       "      <td>1.700773</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:20:00</td>\n",
       "      <td>1.705794</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:22:00</td>\n",
       "      <td>1.710754</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:24:00</td>\n",
       "      <td>1.715654</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:26:00</td>\n",
       "      <td>1.720495</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:28:00</td>\n",
       "      <td>1.725276</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:30:00</td>\n",
       "      <td>1.729998</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:32:00</td>\n",
       "      <td>1.734662</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:34:00</td>\n",
       "      <td>1.739268</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:36:00</td>\n",
       "      <td>1.743815</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:38:00</td>\n",
       "      <td>1.748305</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:40:00</td>\n",
       "      <td>1.752738</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:42:00</td>\n",
       "      <td>1.757114</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:44:00</td>\n",
       "      <td>1.761434</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:46:00</td>\n",
       "      <td>1.765697</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:48:00</td>\n",
       "      <td>1.769905</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:50:00</td>\n",
       "      <td>1.774057</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:52:00</td>\n",
       "      <td>1.758337</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:54:00</td>\n",
       "      <td>1.782196</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:56:00</td>\n",
       "      <td>1.786184</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:58:00</td>\n",
       "      <td>1.790118</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048970</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:00:00</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048971</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:02:00</td>\n",
       "      <td>1.360977</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048972</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:04:00</td>\n",
       "      <td>1.360977</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048973</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:06:00</td>\n",
       "      <td>1.308333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048974</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:08:00</td>\n",
       "      <td>1.308333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048975</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:10:00</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048976</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:12:00</td>\n",
       "      <td>1.435085</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048977</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:14:00</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048978</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:16:00</td>\n",
       "      <td>1.458615</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048979</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:18:00</td>\n",
       "      <td>1.547563</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048980</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:20:00</td>\n",
       "      <td>1.526056</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048981</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:22:00</td>\n",
       "      <td>1.458615</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048982</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:24:00</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048983</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:26:00</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048984</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:28:00</td>\n",
       "      <td>1.589235</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048985</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:30:00</td>\n",
       "      <td>1.629241</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048986</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:32:00</td>\n",
       "      <td>1.726216</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048987</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:34:00</td>\n",
       "      <td>1.435085</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048988</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:36:00</td>\n",
       "      <td>1.360977</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048989</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:38:00</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048990</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:40:00</td>\n",
       "      <td>1.481605</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048991</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:42:00</td>\n",
       "      <td>1.526056</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048992</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:44:00</td>\n",
       "      <td>1.435085</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048993</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:46:00</td>\n",
       "      <td>1.410987</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048994</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:48:00</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048995</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:50:00</td>\n",
       "      <td>1.360977</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048996</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:52:00</td>\n",
       "      <td>1.410987</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048997</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:54:00</td>\n",
       "      <td>1.547563</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048998</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:56:00</td>\n",
       "      <td>1.547563</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048999</th>\n",
       "      <td>9377906289175510514</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017-07-31 17:58:00</td>\n",
       "      <td>1.589235</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5049000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     link_ID        date time_interval_begin  travel_time  \\\n",
       "0        3377906280028510514  2017-03-01 2017-03-01 06:00:00     1.657881   \n",
       "1        3377906280028510514  2017-03-01 2017-03-01 06:02:00     1.658394   \n",
       "2        3377906280028510514  2017-03-01 2017-03-01 06:04:00     1.672953   \n",
       "3        3377906280028510514  2017-03-01 2017-03-01 06:06:00     1.676887   \n",
       "4        3377906280028510514  2017-03-01 2017-03-01 06:08:00     1.680537   \n",
       "5        3377906280028510514  2017-03-01 2017-03-01 06:10:00     1.629241   \n",
       "6        3377906280028510514  2017-03-01 2017-03-01 06:12:00     1.629241   \n",
       "7        3377906280028510514  2017-03-01 2017-03-01 06:14:00     1.629241   \n",
       "8        3377906280028510514  2017-03-01 2017-03-01 06:16:00     1.695692   \n",
       "9        3377906280028510514  2017-03-01 2017-03-01 06:18:00     1.700773   \n",
       "10       3377906280028510514  2017-03-01 2017-03-01 06:20:00     1.705794   \n",
       "11       3377906280028510514  2017-03-01 2017-03-01 06:22:00     1.710754   \n",
       "12       3377906280028510514  2017-03-01 2017-03-01 06:24:00     1.715654   \n",
       "13       3377906280028510514  2017-03-01 2017-03-01 06:26:00     1.720495   \n",
       "14       3377906280028510514  2017-03-01 2017-03-01 06:28:00     1.725276   \n",
       "15       3377906280028510514  2017-03-01 2017-03-01 06:30:00     1.729998   \n",
       "16       3377906280028510514  2017-03-01 2017-03-01 06:32:00     1.734662   \n",
       "17       3377906280028510514  2017-03-01 2017-03-01 06:34:00     1.739268   \n",
       "18       3377906280028510514  2017-03-01 2017-03-01 06:36:00     1.743815   \n",
       "19       3377906280028510514  2017-03-01 2017-03-01 06:38:00     1.748305   \n",
       "20       3377906280028510514  2017-03-01 2017-03-01 06:40:00     1.752738   \n",
       "21       3377906280028510514  2017-03-01 2017-03-01 06:42:00     1.757114   \n",
       "22       3377906280028510514  2017-03-01 2017-03-01 06:44:00     1.761434   \n",
       "23       3377906280028510514  2017-03-01 2017-03-01 06:46:00     1.765697   \n",
       "24       3377906280028510514  2017-03-01 2017-03-01 06:48:00     1.769905   \n",
       "25       3377906280028510514  2017-03-01 2017-03-01 06:50:00     1.774057   \n",
       "26       3377906280028510514  2017-03-01 2017-03-01 06:52:00     1.758337   \n",
       "27       3377906280028510514  2017-03-01 2017-03-01 06:54:00     1.782196   \n",
       "28       3377906280028510514  2017-03-01 2017-03-01 06:56:00     1.786184   \n",
       "29       3377906280028510514  2017-03-01 2017-03-01 06:58:00     1.790118   \n",
       "...                      ...         ...                 ...          ...   \n",
       "5048970  9377906289175510514  2017-07-31 2017-07-31 17:00:00     1.335001   \n",
       "5048971  9377906289175510514  2017-07-31 2017-07-31 17:02:00     1.360977   \n",
       "5048972  9377906289175510514  2017-07-31 2017-07-31 17:04:00     1.360977   \n",
       "5048973  9377906289175510514  2017-07-31 2017-07-31 17:06:00     1.308333   \n",
       "5048974  9377906289175510514  2017-07-31 2017-07-31 17:08:00     1.308333   \n",
       "5048975  9377906289175510514  2017-07-31 2017-07-31 17:10:00     1.386294   \n",
       "5048976  9377906289175510514  2017-07-31 2017-07-31 17:12:00     1.435085   \n",
       "5048977  9377906289175510514  2017-07-31 2017-07-31 17:14:00     1.386294   \n",
       "5048978  9377906289175510514  2017-07-31 2017-07-31 17:16:00     1.458615   \n",
       "5048979  9377906289175510514  2017-07-31 2017-07-31 17:18:00     1.547563   \n",
       "5048980  9377906289175510514  2017-07-31 2017-07-31 17:20:00     1.526056   \n",
       "5048981  9377906289175510514  2017-07-31 2017-07-31 17:22:00     1.458615   \n",
       "5048982  9377906289175510514  2017-07-31 2017-07-31 17:24:00     1.386294   \n",
       "5048983  9377906289175510514  2017-07-31 2017-07-31 17:26:00     1.386294   \n",
       "5048984  9377906289175510514  2017-07-31 2017-07-31 17:28:00     1.589235   \n",
       "5048985  9377906289175510514  2017-07-31 2017-07-31 17:30:00     1.629241   \n",
       "5048986  9377906289175510514  2017-07-31 2017-07-31 17:32:00     1.726216   \n",
       "5048987  9377906289175510514  2017-07-31 2017-07-31 17:34:00     1.435085   \n",
       "5048988  9377906289175510514  2017-07-31 2017-07-31 17:36:00     1.360977   \n",
       "5048989  9377906289175510514  2017-07-31 2017-07-31 17:38:00     1.386294   \n",
       "5048990  9377906289175510514  2017-07-31 2017-07-31 17:40:00     1.481605   \n",
       "5048991  9377906289175510514  2017-07-31 2017-07-31 17:42:00     1.526056   \n",
       "5048992  9377906289175510514  2017-07-31 2017-07-31 17:44:00     1.435085   \n",
       "5048993  9377906289175510514  2017-07-31 2017-07-31 17:46:00     1.410987   \n",
       "5048994  9377906289175510514  2017-07-31 2017-07-31 17:48:00     1.386294   \n",
       "5048995  9377906289175510514  2017-07-31 2017-07-31 17:50:00     1.360977   \n",
       "5048996  9377906289175510514  2017-07-31 2017-07-31 17:52:00     1.410987   \n",
       "5048997  9377906289175510514  2017-07-31 2017-07-31 17:54:00     1.547563   \n",
       "5048998  9377906289175510514  2017-07-31 2017-07-31 17:56:00     1.547563   \n",
       "5048999  9377906289175510514  2017-07-31 2017-07-31 17:58:00     1.589235   \n",
       "\n",
       "        imputation1  \n",
       "0              True  \n",
       "1              True  \n",
       "2              True  \n",
       "3              True  \n",
       "4              True  \n",
       "5             False  \n",
       "6             False  \n",
       "7             False  \n",
       "8              True  \n",
       "9              True  \n",
       "10             True  \n",
       "11             True  \n",
       "12             True  \n",
       "13             True  \n",
       "14             True  \n",
       "15             True  \n",
       "16             True  \n",
       "17             True  \n",
       "18             True  \n",
       "19             True  \n",
       "20             True  \n",
       "21             True  \n",
       "22             True  \n",
       "23             True  \n",
       "24             True  \n",
       "25             True  \n",
       "26             True  \n",
       "27             True  \n",
       "28             True  \n",
       "29             True  \n",
       "...             ...  \n",
       "5048970       False  \n",
       "5048971       False  \n",
       "5048972       False  \n",
       "5048973       False  \n",
       "5048974       False  \n",
       "5048975       False  \n",
       "5048976       False  \n",
       "5048977       False  \n",
       "5048978       False  \n",
       "5048979       False  \n",
       "5048980       False  \n",
       "5048981       False  \n",
       "5048982       False  \n",
       "5048983       False  \n",
       "5048984       False  \n",
       "5048985       False  \n",
       "5048986       False  \n",
       "5048987       False  \n",
       "5048988       False  \n",
       "5048989       False  \n",
       "5048990       False  \n",
       "5048991       False  \n",
       "5048992       False  \n",
       "5048993       False  \n",
       "5048994       False  \n",
       "5048995       False  \n",
       "5048996       False  \n",
       "5048997       False  \n",
       "5048998       False  \n",
       "5048999       False  \n",
       "\n",
       "[5049000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/com_training.txt', delimiter=';', parse_dates=['time_interval_begin'], dtype={'link_ID': object})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 时间特征\n",
    "def create_lagging(df, df_original, i):\n",
    "    df1 = df_original.copy()\n",
    "    df1['time_interval_begin'] = df1['time_interval_begin'] + pd.DateOffset(minutes=i * 2)\n",
    "    df1 = df1.rename(columns={'travel_time': 'lagging' + str(i)})\n",
    "    df2 = pd.merge(df, df1[['link_ID', 'time_interval_begin', 'lagging' + str(i)]],\n",
    "                   on=['link_ID', 'time_interval_begin'],\n",
    "                   how='left')\n",
    "    return df2\n",
    "\n",
    "df1 = create_lagging(df, df, 1)\n",
    "\n",
    "for i in range(2, 6):\n",
    "    df1 = create_lagging(df1, df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 长、宽特征\n",
    "link_infos = pd.read_csv('data/gy_contest_link_info.txt', delimiter=';', dtype={'link_ID': object})\n",
    "link_tops = pd.read_csv('data/gy_contest_link_top.txt', delimiter=';', dtype={'link_ID': object})\n",
    "link_tops['in_links'] = link_tops['in_links'].str.len().apply(lambda x: np.floor(x / 19))\n",
    "link_tops['out_links'] = link_tops['out_links'].str.len().apply(lambda x: np.floor(x / 19))\n",
    "link_tops = link_tops.fillna(0)\n",
    "link_infos = pd.merge(link_infos, link_tops, on=['link_ID'], how='left')\n",
    "link_infos['links_num'] = link_infos[\"in_links\"].astype('str') + \",\" + link_infos[\"out_links\"].astype('str')\n",
    "link_infos['area'] = link_infos['length'] * link_infos['width']\n",
    "df2 = pd.merge(df1, link_infos[['link_ID', 'length', 'width', 'links_num', 'area']], on=['link_ID'], how='left')\n",
    "\n",
    "# links_num feature\n",
    "df2.loc[df2['links_num'].isin(['0.0,2.0', '2.0,0.0', '1.0,0.0']), 'links_num'] = 'other'\n",
    "# df.boxplot(by=['links_num'], column='travel_time')\n",
    "# plt.show()\n",
    "\n",
    "# vacation feature\n",
    "df2.loc[df2['date'].isin(\n",
    "    ['2017-04-02', '2017-04-03', '2017-04-04', '2017-04-29', '2017-04-30', '2017-05-01',\n",
    "     '2017-05-28', '2017-05-29', '2017-05-30']), 'vacation'] = 1\n",
    "df2.loc[~df2['date'].isin(\n",
    "    ['2017-04-02', '2017-04-03', '2017-04-04', '2017-04-29', '2017-04-30', '2017-05-01',\n",
    "     '2017-05-28', '2017-05-29', '2017-05-30']), 'vacation'] = 0\n",
    "\n",
    "# minute_series for CV\n",
    "# 早午晚都编码成0-178\n",
    "df2.loc[df2['time_interval_begin'].dt.hour.isin([6, 7, 8]), 'minute_series'] = \\\n",
    "    df2['time_interval_begin'].dt.minute + (df2['time_interval_begin'].dt.hour - 6) * 60\n",
    "\n",
    "df2.loc[df2['time_interval_begin'].dt.hour.isin([13, 14, 15]), 'minute_series'] = \\\n",
    "    df2['time_interval_begin'].dt.minute + (df2['time_interval_begin'].dt.hour - 13) * 60\n",
    "\n",
    "df2.loc[df2['time_interval_begin'].dt.hour.isin([16, 17, 18]), 'minute_series'] = \\\n",
    "    df2['time_interval_begin'].dt.minute + (df2['time_interval_begin'].dt.hour - 16) * 60\n",
    "\n",
    "# day_of_week_en feature\n",
    "df2['day_of_week'] = df2['time_interval_begin'].map(lambda x: x.weekday() + 1)\n",
    "df2.loc[df2['day_of_week'].isin([1, 2, 3]), 'day_of_week_en'] = 1\n",
    "df2.loc[df2['day_of_week'].isin([4, 5]), 'day_of_week_en'] = 2\n",
    "df2.loc[df2['day_of_week'].isin([6, 7]), 'day_of_week_en'] = 3\n",
    "\n",
    "# hour_en feature\n",
    "df2.loc[df['time_interval_begin'].dt.hour.isin([6, 7, 8]), 'hour_en'] = 1\n",
    "df2.loc[df['time_interval_begin'].dt.hour.isin([13, 14, 15]), 'hour_en'] = 2\n",
    "df2.loc[df['time_interval_begin'].dt.hour.isin([16, 17, 18]), 'hour_en'] = 3\n",
    "\n",
    "# week_hour feature\n",
    "df2['week_hour'] = df2[\"day_of_week_en\"].astype('str') + \",\" + df2[\"hour_en\"].astype('str')\n",
    "\n",
    "# df2.boxplot(by=['week_hour'], column='travel_time')\n",
    "# plt.show()\n",
    "\n",
    "df2 = pd.get_dummies(df2, columns=['week_hour', 'links_num', 'width'])\n",
    "\n",
    "# ID Label Encode\n",
    "def mean_time(group):\n",
    "    group['link_ID_en'] = group['travel_time'].mean()\n",
    "    return group\n",
    "\n",
    "df2 = df2.groupby('link_ID').apply(mean_time)\n",
    "sorted_link = np.sort(df2['link_ID_en'].unique())\n",
    "df2['link_ID_en'] = df2['link_ID_en'].map(lambda x: np.argmin(x >= sorted_link))\n",
    "# df.boxplot(by=['link_ID_en'], column='travel_time')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv('data/training.txt', header=True, index=None, sep=';', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgboost_submit(df, params):\n",
    "    train_df = df.loc[df['time_interval_begin'] < pd.to_datetime('2017-07-01')]\n",
    "\n",
    "    train_df = train_df.dropna()\n",
    "    X = train_df[train_feature].values\n",
    "    y = train_df['travel_time'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "    eval_set = [(X_test, y_test)]\n",
    "    regressor = xgb.XGBRegressor(learning_rate=params['learning_rate'], n_estimators=params['n_estimators'],\n",
    "                                 booster='gbtree', objective='reg:linear', n_jobs=-1, subsample=params['subsample'],\n",
    "                                 colsample_bytree=params['colsample_bytree'], random_state=0,\n",
    "                                 max_depth=params['max_depth'], gamma=params['gamma'],\n",
    "                                 min_child_weight=params['min_child_weight'], reg_alpha=params['reg_alpha'])\n",
    "    regressor.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric=mape_ln,\n",
    "                  eval_set=eval_set)\n",
    "    feature_vis(regressor, train_feature)\n",
    "    joblib.dump(regressor, 'model/xgbr.pkl')\n",
    "    print regressor\n",
    "    submission(train_feature, regressor, df, 'submission/xgbr1.txt', 'submission/xgbr2.txt', 'submission/xgbr3.txt',\n",
    "               'submission/xgbr4.txt')\n",
    "\n",
    "\n",
    "def fit_evaluate(df, df_test, params):\n",
    "    df = df.dropna()\n",
    "    X = df[train_feature].values\n",
    "    y = df['travel_time'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "    df_test = df_test[valid_feature].values\n",
    "    valid_data = bucket_data(df_test)\n",
    "\n",
    "    eval_set = [(X_test, y_test)]\n",
    "    regressor = xgb.XGBRegressor(learning_rate=params['learning_rate'], n_estimators=params['n_estimators'],\n",
    "                                 objective='reg:linear', subsample=params['subsample'],\n",
    "                                 colsample_bytree=params['colsample_bytree'],\n",
    "                                 max_depth=params['max_depth'], gamma=params['gamma'],\n",
    "                                 min_child_weight=params['min_child_weight'], reg_alpha=params['reg_alpha'])\n",
    "    regressor.fit(X_train, y_train, verbose=False, early_stopping_rounds=10, eval_metric=mape_ln,\n",
    "                  eval_set=eval_set)\n",
    "    # feature_vis(regressor, train_feature)\n",
    "\n",
    "    return regressor, cross_valid(regressor, valid_data,\n",
    "                                  lagging=lagging), regressor.best_iteration, regressor.best_score\n",
    "\n",
    "\n",
    "def train(df, params, best, vis=False):\n",
    "    train1 = df.loc[df['time_interval_begin'] <= pd.to_datetime('2017-03-24')]  # 0301-0324\n",
    "    train2 = df.loc[\n",
    "        (df['time_interval_begin'] > pd.to_datetime('2017-03-24')) & (\n",
    "            df['time_interval_begin'] <= pd.to_datetime('2017-04-18'))]  # 0324-0418\n",
    "    train3 = df.loc[\n",
    "        (df['time_interval_begin'] > pd.to_datetime('2017-04-18')) & (\n",
    "            df['time_interval_begin'] <= pd.to_datetime('2017-05-12'))]  # 0418-0512\n",
    "    train4 = df.loc[\n",
    "        (df['time_interval_begin'] > pd.to_datetime('2017-05-12')) & (\n",
    "            df['time_interval_begin'] <= pd.to_datetime('2017-06-06'))]  # 0512-0606\n",
    "    train5 = df.loc[\n",
    "        (df['time_interval_begin'] > pd.to_datetime('2017-06-06')) & (\n",
    "            df['time_interval_begin'] <= pd.to_datetime('2017-06-30'))]  # 0606-0630\n",
    "\n",
    "    regressor, loss1, best_iteration1, best_score1 = fit_evaluate(pd.concat([train1, train2, train3, train4]), train5,\n",
    "                                                                  params)\n",
    "    print (best_iteration1, best_score1, loss1)\n",
    "\n",
    "    regressor, loss2, best_iteration2, best_score2 = fit_evaluate(pd.concat([train1, train2, train3, train5]), train4,\n",
    "                                                                  params)\n",
    "    print (best_iteration2, best_score2, loss2)\n",
    "\n",
    "    regressor, loss3, best_iteration3, best_score3 = fit_evaluate(pd.concat([train1, train2, train4, train5]), train3,\n",
    "                                                                  params)\n",
    "    print (best_iteration3, best_score3, loss3)\n",
    "\n",
    "    regressor, loss4, best_iteration4, best_score4 = fit_evaluate(pd.concat([train1, train3, train4, train5]), train2,\n",
    "                                                                  params)\n",
    "    print (best_iteration4, best_score4, loss4)\n",
    "\n",
    "    regressor, loss5, best_iteration5, best_score5 = fit_evaluate(pd.concat([train2, train3, train4, train5]), train1,\n",
    "                                                                  params)\n",
    "    print (best_iteration5, best_score5, loss5)\n",
    "\n",
    "    if vis:\n",
    "        xgb.plot_tree(regressor, num_trees=5)\n",
    "        results = regressor.evals_result()\n",
    "        epochs = len(results['validation_0']['rmse'])\n",
    "        x_axis = range(0, epochs)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(x_axis, results['validation_0']['rmse'], label='Train')\n",
    "        ax.plot(x_axis, results['validation_1']['rmse'], label='Test')\n",
    "        ax.legend()\n",
    "        plt.ylabel('rmse Loss')\n",
    "        plt.ylim((0.2, 0.3))\n",
    "        plt.show()\n",
    "\n",
    "    loss = [loss1, loss2, loss3, loss4, loss5]\n",
    "    params['loss_std'] = np.std(loss)\n",
    "    params['loss'] = str(loss)\n",
    "    params['mean_loss'] = np.mean(loss)\n",
    "    params['n_estimators'] = str([best_iteration1, best_iteration2, best_iteration3, best_iteration4, best_iteration5])\n",
    "    params['best_score'] = str([best_score1, best_score2, best_score3, best_score4, best_score5])\n",
    "\n",
    "    print str(params)\n",
    "    if np.mean(loss) <= best:\n",
    "        best = np.mean(loss)\n",
    "        print \"best with: \" + str(params)\n",
    "#         feature_vis(regressor, train_feature)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['length', 'vacation', 'day_of_week_en', 'week_hour_1.0,1.0', 'week_hour_1.0,2.0', 'week_hour_1.0,3.0', 'week_hour_2.0,1.0', 'week_hour_2.0,2.0', 'week_hour_2.0,3.0', 'week_hour_3.0,1.0', 'week_hour_3.0,2.0', 'week_hour_3.0,3.0', 'links_num_0.0,1.0', 'links_num_1.0,1.0', 'links_num_1.0,2.0', 'links_num_1.0,3.0', 'links_num_1.0,4.0', 'links_num_2.0,1.0', 'links_num_2.0,2.0', 'links_num_3.0,1.0', 'links_num_4.0,1.0', 'links_num_other', 'width_3', 'width_6', 'width_9', 'width_12', 'width_15', 'link_ID_en', 'lagging5', 'lagging4', 'lagging3', 'lagging2', 'lagging1']\n"
     ]
    }
   ],
   "source": [
    "# train_feature中包括lagging特征\n",
    "# valid_feature中不包括lagging特征，包括['minute_series', 'travel_time']\n",
    "\n",
    "lagging = 5\n",
    "df = pd.read_csv('data/training.txt', delimiter=';', parse_dates=['time_interval_begin'], dtype={'link_ID': object})\n",
    "lagging_feature = ['lagging%01d' % e for e in range(lagging, 0, -1)]  # 生成lagging特征\n",
    "base_feature = [x for x in df.columns.values.tolist() if x not in ['time_interval_begin', 'link_ID', 'link_ID_int',\n",
    "                                                                   'date', 'travel_time', 'imputation1',\n",
    "                                                                   'minute_series', 'area', 'hour_en', 'day_of_week']]\n",
    "base_feature = [x for x in base_feature if x not in lagging_feature]\n",
    "train_feature = list(base_feature)\n",
    "train_feature.extend(lagging_feature)\n",
    "valid_feature = list(base_feature)\n",
    "valid_feature.extend(['minute_series', 'travel_time'])\n",
    "print train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.865125, 0.80786214674780721)\n",
      "(0, 0.866922, 0.8240044555484739)\n",
      "(0, 0.866211, 0.79502990524713169)\n",
      "(0, 0.866606, 0.79436080458845282)\n",
      "(0, 0.866445, 0.77696943932234408)\n",
      "{'loss': '[0.80786214674780721, 0.8240044555484739, 0.79502990524713169, 0.79436080458845282, 0.77696943932234408]', 'reg_alpha': 2, 'colsample_bytree': 0.6, 'learning_rate': 0.05, 'min_child_weight': 1, 'best_score': '[0.865125, 0.866922, 0.866211, 0.866606, 0.866445]', 'n_estimators': '[0, 0, 0, 0, 0]', 'subsample': 0.6, 'mean_loss': 0.79964535029084194, 'loss_std': 0.015648050661031108, 'max_depth': 7, 'gamma': 0}\n",
      "best with: {'loss': '[0.80786214674780721, 0.8240044555484739, 0.79502990524713169, 0.79436080458845282, 0.77696943932234408]', 'reg_alpha': 2, 'colsample_bytree': 0.6, 'learning_rate': 0.05, 'min_child_weight': 1, 'best_score': '[0.865125, 0.866922, 0.866211, 0.866606, 0.866445]', 'n_estimators': '[0, 0, 0, 0, 0]', 'subsample': 0.6, 'mean_loss': 0.79964535029084194, 'loss_std': 0.015648050661031108, 'max_depth': 7, 'gamma': 0}\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "params_grid = {\n",
    "    'learning_rate': [0.05],\n",
    "    'n_estimators': [100],\n",
    "    'subsample': [0.6],\n",
    "    'colsample_bytree': [0.6],\n",
    "    'max_depth': [7],\n",
    "    'min_child_weight': [1],\n",
    "    'reg_alpha': [2],\n",
    "    'gamma': [0]\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(params_grid)\n",
    "best = 1\n",
    "\n",
    "for params in grid:\n",
    "    best = train(df, params, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# key为倒数第二位，value为余下特征\n",
    "def bucket_data(lines):  # lines是df[valid_feature].values\n",
    "    bucket = {}\n",
    "    for line in lines:\n",
    "        time_series = line[-2]  #　倒数第二位为time_series特征，0-178\n",
    "        bucket[time_series] = []  # bucket的keys为0-178\n",
    "    for line in lines:\n",
    "        time_series, y1 = line[-2:]  # 倒数第二位，y1最后一位\n",
    "        line = np.delete(line, -2, axis=0)  # 删除倒数第二位\n",
    "        bucket[time_series].append(line)  # key为倒数第二位，value为余下特征\n",
    "    return bucket\n",
    "\n",
    "\n",
    "def cross_valid(regressor, bucket, lagging):\n",
    "    valid_loss = []\n",
    "    last = [[] for i in range(len(bucket[bucket.keys()[0]]))]\n",
    "    for time_series in sorted(bucket.keys(), key=float):\n",
    "        if time_series >= 120:\n",
    "            if int(time_series) in range(120, 120 + lagging * 2, 2):\n",
    "                last = np.concatenate((last, np.array(bucket[time_series], dtype=float)[:, -1].reshape(-1, 1)), axis=1)\n",
    "            else:\n",
    "                batch = np.array(bucket[time_series], dtype=float)\n",
    "                y = batch[:, -1]\n",
    "                batch = np.delete(batch, -1, axis=1)\n",
    "                batch = np.concatenate((batch, last), axis=1)\n",
    "                y_pre = regressor.predict(batch)\n",
    "                last = np.delete(last, 0, axis=1)\n",
    "                last = np.concatenate((last, y_pre.reshape(-1, 1)), axis=1)\n",
    "                loss = np.mean(abs(np.expm1(y) - np.expm1(y_pre)) / np.expm1(y))\n",
    "                valid_loss.append(loss)\n",
    "    # print 'day: %d loss: %f' % (int(day), day_loss)\n",
    "    return np.mean(valid_loss)\n",
    "\n",
    "\n",
    "def mape_ln(y, d):\n",
    "    c = d.get_label()\n",
    "    result = np.sum(np.abs((np.expm1(y) - np.expm1(c)) / np.expm1(c))) / len(c)\n",
    "    return \"mape\", result\n",
    "\n",
    "\n",
    "def feature_vis(regressor, train_feature):\n",
    "    importances = regressor.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    selected_features = [train_feature[e] for e in indices]\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.title(\"train_feature importances\")\n",
    "    plt.bar(range(len(train_feature)), importances[indices],\n",
    "            color=\"r\", align=\"center\")\n",
    "    plt.xticks(range(len(selected_features)), selected_features, rotation=70)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------Submission ---------------------------------------------\n",
    "\n",
    "\n",
    "def submission(train_feature, regressor, df, file1, file2, file3, file4):\n",
    "    test_df = df.loc[((df['time_interval_begin'].dt.year == 2017) & (df['time_interval_begin'].dt.month == 7)\n",
    "                      & (df['time_interval_begin'].dt.hour.isin([7, 14, 17])) & (\n",
    "                          df['time_interval_begin'].dt.minute == 58))].copy()\n",
    "\n",
    "    test_df['lagging5'] = test_df['lagging4']\n",
    "    test_df['lagging4'] = test_df['lagging3']\n",
    "    test_df['lagging3'] = test_df['lagging2']\n",
    "    test_df['lagging2'] = test_df['lagging1']\n",
    "    test_df['lagging1'] = test_df['travel_time']\n",
    "\n",
    "    with open(file1, 'w'):\n",
    "        pass\n",
    "    with open(file2, 'w'):\n",
    "        pass\n",
    "    with open(file3, 'w'):\n",
    "        pass\n",
    "    with open(file4, 'w'):\n",
    "        pass\n",
    "\n",
    "    for i in range(30):\n",
    "        test_X = test_df[train_feature]\n",
    "        y_prediction = regressor.predict(test_X.values)\n",
    "\n",
    "        test_df['lagging5'] = test_df['lagging4']\n",
    "        test_df['lagging4'] = test_df['lagging3']\n",
    "        test_df['lagging3'] = test_df['lagging2']\n",
    "        test_df['lagging2'] = test_df['lagging1']\n",
    "        test_df['lagging1'] = y_prediction\n",
    "\n",
    "        test_df['predicted'] = np.expm1(y_prediction)\n",
    "        test_df['time_interval_begin'] = test_df['time_interval_begin'] + pd.DateOffset(minutes=2)\n",
    "        test_df['time_interval'] = test_df['time_interval_begin'].map(\n",
    "            lambda x: '[' + str(x) + ',' + str(x + pd.DateOffset(minutes=2)) + ')')\n",
    "        test_df.time_interval = test_df.time_interval.astype(object)\n",
    "        if i < 7:\n",
    "            test_df[['link_ID', 'date', 'time_interval', 'predicted']].to_csv(file1, mode='a', header=False,\n",
    "                                                                              index=False,\n",
    "                                                                              sep=';')\n",
    "        elif (7 <= i) and (i < 14):\n",
    "            test_df[['link_ID', 'date', 'time_interval', 'predicted']].to_csv(file2, mode='a', header=False,\n",
    "                                                                              index=False,\n",
    "                                                                              sep=';')\n",
    "        elif (14 <= i) and (i < 22):\n",
    "            test_df[['link_ID', 'date', 'time_interval', 'predicted']].to_csv(file3, mode='a', header=False,\n",
    "                                                                              index=False,\n",
    "                                                                              sep=';')\n",
    "        else:\n",
    "            test_df[['link_ID', 'date', 'time_interval', 'predicted']].to_csv(file4, mode='a', header=False,\n",
    "                                                                              index=False,\n",
    "                                                                              sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.99822675145421"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.80786214674780721+0.8240044555484739+0.79502990524713169+0.79436080458845282+0.77696943932234408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20035464970915806"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- 3.99822675145421/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
